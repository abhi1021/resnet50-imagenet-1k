{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ImageNet / ImageNette Model (Local Mac)\n",
    "This notebook trains a model on **ImageNet or ImageNette** locally on Mac with the **modular codebase**.\n",
    "\n",
    "**Supported Datasets:**\n",
    "- **ImageNet-1K**: Full 1000-class dataset (~1.28M train, 50K val)\n",
    "- **ImageNette**: 10-class ImageNet subset (fast for quick trials)\n",
    "- **Custom ImageNet subsets**: Any ImageFolder-compatible dataset\n",
    "\n",
    "**Training Command Example (ImageNette):**\n",
    "```bash\n",
    "python train.py --model resnet50 --dataset imagenet --data-dir ./imagenette2-160 \\\n",
    "    --epochs 3 --batch-size 128 --scheduler onecycle\n",
    "```\n",
    "\n",
    "**Required Dataset Structure:**\n",
    "```\n",
    "your_dataset_dir/\n",
    "    train/\n",
    "        n01440764/  # class folders\n",
    "            image1.JPEG\n",
    "            ...\n",
    "        n01443537/\n",
    "            ...\n",
    "    val/\n",
    "        n01440764/\n",
    "            ...\n",
    "```\n",
    "\n",
    "**Modular Structure:**\n",
    "- Datasets in `data_loaders/` - CIFAR-100, ImageNet, easy to extend\n",
    "- Models in `models/` - ResNet50, WideResNet, clean separation\n",
    "- Training in `training/` - Optimizer, scheduler, LR finder  \n",
    "- Utils in `utils/` - Checkpointing, metrics, HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENVIRONMENT INFORMATION\n",
      "======================================================================\n",
      "Python Version: 3.12.3 (main, Oct  7 2025, 19:27:29) [Clang 17.0.0 (clang-1700.0.13.5)]\n",
      "Platform: macOS-15.5-arm64-arm-64bit\n",
      "Processor: arm\n",
      "Working Directory: /Users/pandurang/projects/pandurang/resnet50-imagenet-1k\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENVIRONMENT INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Working Directory: {os.getcwd()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU/MPS Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PYTORCH & GPU DETECTION\n",
      "======================================================================\n",
      "PyTorch Version: 2.9.0\n",
      "âœ“ Apple MPS (Metal Performance Shaders) is available\n",
      "  This Mac has Apple Silicon GPU acceleration\n",
      "âœ“ Using device: mps\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PYTORCH & GPU DETECTION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    \n",
    "    # Check for CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"âœ“ CUDA is available\")\n",
    "        print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "        device = torch.device('cuda')\n",
    "    # Check for MPS (Apple Silicon)\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        print(f\"âœ“ Apple MPS (Metal Performance Shaders) is available\")\n",
    "        print(f\"  This Mac has Apple Silicon GPU acceleration\")\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        print(f\"âš  No GPU detected. Training will use CPU\")\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    print(f\"âœ“ Using device: {device}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš  PyTorch not installed. Will install dependencies in next step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.0.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.9.0)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: torchinfo>=1.8.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.8.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (3.10.7)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2.2.6)\n",
      "Requirement already satisfied: plotille>=5.0.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (5.0.0)\n",
      "Requirement already satisfied: albumentations>=1.3.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (2.0.8)\n",
      "Requirement already satisfied: huggingface_hub>=0.20.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.35.3)\n",
      "Requirement already satisfied: filelock in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torchvision>=0.15.0->-r requirements.txt (line 2)) (12.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 8)) (1.16.2)\n",
      "Requirement already satisfied: PyYAML in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 8)) (6.0.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 8)) (2.12.3)\n",
      "Requirement already satisfied: albucore==0.0.24 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 8)) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 8)) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements.txt (line 8)) (4.2.1)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements.txt (line 8)) (6.5.3)\n",
      "Requirement already satisfied: requests in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from huggingface_hub>=0.20.0->-r requirements.txt (line 9)) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from huggingface_hub>=0.20.0->-r requirements.txt (line 9)) (1.1.10)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 8)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 8)) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 9)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 9)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 9)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 9)) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies from requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Verify Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LIBRARY VERSIONS\n",
      "======================================================================\n",
      "PyTorch: 2.9.0\n",
      "TorchVision: 0.24.0\n",
      "NumPy: 2.2.6\n",
      "Matplotlib: 3.10.7\n",
      "Albumentations: 2.0.8\n",
      "TQDM: 4.67.1\n",
      "======================================================================\n",
      "âœ“ All dependencies successfully imported\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchsummary\n",
    "import torchinfo\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import numpy\n",
    "import plotille\n",
    "import albumentations\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LIBRARY VERSIONS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"TorchVision: {torchvision.__version__}\")\n",
    "print(f\"NumPy: {numpy.__version__}\")\n",
    "print(f\"Matplotlib: {matplotlib.__version__}\")\n",
    "print(f\"Albumentations: {albumentations.__version__}\")\n",
    "print(f\"TQDM: {tqdm.__version__}\")\n",
    "print(\"=\"*70)\n",
    "print(\"âœ“ All dependencies successfully imported\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFYING TRAINING FILES AND MODULAR STRUCTURE\n",
      "======================================================================\n",
      "\n",
      "Required Files:\n",
      "âœ“ train.py\n",
      "âœ“ config.json\n",
      "âœ“ requirements.txt\n",
      "\n",
      "Modular Directories:\n",
      "âœ“ data_loaders/\n",
      "âœ“ models/\n",
      "âœ“ training/\n",
      "âœ“ utils/\n",
      "======================================================================\n",
      "âœ“ All required files and modular structure verified!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFYING TRAINING FILES AND MODULAR STRUCTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check required files\n",
    "required_files = [\n",
    "    'train.py',\n",
    "    'config.json',\n",
    "    'requirements.txt'\n",
    "]\n",
    "\n",
    "print(\"\\nRequired Files:\")\n",
    "files_ok = True\n",
    "for file in required_files:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"âœ“\" if exists else \"âœ—\"\n",
    "    print(f\"{status} {file}\")\n",
    "    if not exists:\n",
    "        files_ok = False\n",
    "\n",
    "# Check modular directories\n",
    "required_dirs = ['data_loaders', 'models', 'training', 'utils']\n",
    "print(\"\\nModular Directories:\")\n",
    "dirs_ok = True\n",
    "for dir in required_dirs:\n",
    "    exists = os.path.isdir(dir)\n",
    "    status = \"âœ“\" if exists else \"âœ—\"\n",
    "    print(f\"{status} {dir}/\")\n",
    "    if not exists:\n",
    "        dirs_ok = False\n",
    "\n",
    "print(\"=\"*70)\n",
    "if files_ok and dirs_ok:\n",
    "    print(\"âœ“ All required files and modular structure verified!\")\n",
    "else:\n",
    "    print(\"âš  Some files or directories are missing. Please check your directory.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration for ImageNet / ImageNette\n",
    "\n",
    "The training will use the following configuration with the **modular codebase**:\n",
    "\n",
    "### Model Options:\n",
    "- **resnet50** - ResNet-50 (25.6M parameters, from `models/resnet50.py`)\n",
    "- **wideresnet28-10** - WideResNet-28-10 (36.5M parameters, from `models/wideresnet.py`)\n",
    "\n",
    "### Dataset: ImageNet / ImageNette\n",
    "- **ImageNette-160**: 10 classes, 160x160 images (resized to 224x224)\n",
    "- **ImageNet-1K**: 1000 classes, variable size images (resized to 224x224)\n",
    "- Number of classes automatically detected from dataset directory\n",
    "\n",
    "### Training Parameters:\n",
    "- **Epochs**: 3-10 for quick trials (ImageNette), 90-100 for full training\n",
    "- **Batch Size**: 128-256 (adjust based on GPU memory)\n",
    "- **Scheduler**: OneCycle Learning Rate Policy or Cosine\n",
    "- **LR Finder**: Optional - automatically finds optimal learning rate\n",
    "\n",
    "### ImageNet-Specific Features:\n",
    "- **Transforms**: RandomResizedCrop(224), ColorJitter, HorizontalFlip\n",
    "- **Validation**: Resize(256) â†’ CenterCrop(224)\n",
    "- **Mixed Precision**: Enabled by default (if supported)\n",
    "- **MixUp**: Enabled (alpha=0.2)\n",
    "- **Label Smoothing**: 0.1\n",
    "\n",
    "### Command Line Parameter:\n",
    "**IMPORTANT**: You must specify `--data-dir` pointing to your ImageNet/ImageNette directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training on ImageNet / ImageNette\n",
    "\n",
    "**Before running:** Ensure your dataset is downloaded and the path is correct!\n",
    "\n",
    "**Training will:**\n",
    "1. Load ImageNet/ImageNette from the specified `--data-dir`\n",
    "2. Automatically detect number of classes from directory structure\n",
    "3. Optionally run LR Finder (if `--lr-finder` is specified)\n",
    "4. Train with OneCycle scheduler and advanced augmentations\n",
    "5. Save checkpoints to `checkpoint_N/` folder\n",
    "\n",
    "**Example Commands:**\n",
    "\n",
    "```bash\n",
    "# ImageNette quick trial (3 epochs)\n",
    "python train.py --model resnet50 --dataset imagenet --data-dir ./imagenette2-160 \\\n",
    "    --epochs 3 --batch-size 128\n",
    "\n",
    "# ImageNette with LR finder\n",
    "python train.py --model resnet50 --dataset imagenet --data-dir ./imagenette2-160 \\\n",
    "    --epochs 10 --batch-size 128 --scheduler onecycle --lr-finder\n",
    "\n",
    "# Full ImageNet training (requires powerful GPU)\n",
    "python train.py --model resnet50 --dataset imagenet --data-dir /path/to/imagenet \\\n",
    "    --epochs 90 --batch-size 256 --scheduler onecycle\n",
    "```\n",
    "\n",
    "**Note:** Update the `--data-dir` parameter below with your actual dataset path!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Using Apple Silicon GPU (MPS)\n",
      "âš  Warning: num_workers=4 may be too high for MPS.\n",
      "   Recommended: 0-2 workers for Apple Silicon GPU\n",
      "   Using num_workers=2 for better performance\n",
      "âš  Warning: Disabling mixed precision for MPS (limited support)\n",
      "\n",
      "Loading ImageNet dataset from: ./imagenette2-160\n",
      "ImageNet dataset loaded:\n",
      "  Training samples: 9,469\n",
      "  Validation samples: 3,925\n",
      "  Number of classes: 10\n",
      "Detected 10 classes in dataset\n",
      "/Users/pandurang/.pyenv/versions/erav4-sess9/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/pandurang/.pyenv/versions/erav4-sess9/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "\n",
      "Training resnet50-pytorch for 3 epochs on ImageNet (10 classes)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Model Architecture Summary\n",
      "======================================================================\n",
      "Device: mps\n",
      "Model: resnet50-pytorch\n",
      "Number of classes: 10\n",
      "Mixed Precision: False\n",
      "MixUp: True (alpha=0.2)\n",
      "Label Smoothing: 0.1\n",
      "\n",
      "Total Parameters: 23,528,522\n",
      "Trainable Parameters: 23,528,522\n",
      "Non-trainable Parameters: 0\n",
      "\n",
      "Model Summary:\n",
      "\n",
      "âš  torchsummary.summary failed: slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device\n",
      "Falling back to torchinfo...\n",
      "\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet                                   [1, 10]                   --\n",
      "â”œâ”€Conv2d: 1-1                            [1, 64, 112, 112]         9,408\n",
      "â”œâ”€BatchNorm2d: 1-2                       [1, 64, 112, 112]         128\n",
      "â”œâ”€ReLU: 1-3                              [1, 64, 112, 112]         --\n",
      "â”œâ”€MaxPool2d: 1-4                         [1, 64, 56, 56]           --\n",
      "â”œâ”€Sequential: 1-5                        [1, 256, 56, 56]          --\n",
      "â”‚    â””â”€Bottleneck: 2-1                   [1, 256, 56, 56]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-1                  [1, 64, 56, 56]           4,096\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-2             [1, 64, 56, 56]           128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-3                    [1, 64, 56, 56]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-4                  [1, 64, 56, 56]           36,864\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-5             [1, 64, 56, 56]           128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-6                    [1, 64, 56, 56]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-7                  [1, 256, 56, 56]          16,384\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-8             [1, 256, 56, 56]          512\n",
      "â”‚    â”‚    â””â”€Sequential: 3-9              [1, 256, 56, 56]          16,896\n",
      "â”‚    â”‚    â””â”€ReLU: 3-10                   [1, 256, 56, 56]          --\n",
      "â”‚    â””â”€Bottleneck: 2-2                   [1, 256, 56, 56]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-11                 [1, 64, 56, 56]           16,384\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-12            [1, 64, 56, 56]           128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-13                   [1, 64, 56, 56]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-14                 [1, 64, 56, 56]           36,864\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-15            [1, 64, 56, 56]           128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-16                   [1, 64, 56, 56]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-17                 [1, 256, 56, 56]          16,384\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-18            [1, 256, 56, 56]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-19                   [1, 256, 56, 56]          --\n",
      "â”‚    â””â”€Bottleneck: 2-3                   [1, 256, 56, 56]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-20                 [1, 64, 56, 56]           16,384\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-21            [1, 64, 56, 56]           128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-22                   [1, 64, 56, 56]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-23                 [1, 64, 56, 56]           36,864\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-24            [1, 64, 56, 56]           128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-25                   [1, 64, 56, 56]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-26                 [1, 256, 56, 56]          16,384\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-27            [1, 256, 56, 56]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-28                   [1, 256, 56, 56]          --\n",
      "â”œâ”€Sequential: 1-6                        [1, 512, 28, 28]          --\n",
      "â”‚    â””â”€Bottleneck: 2-4                   [1, 512, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-29                 [1, 128, 56, 56]          32,768\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-30            [1, 128, 56, 56]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-31                   [1, 128, 56, 56]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-32                 [1, 128, 28, 28]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-33            [1, 128, 28, 28]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-34                   [1, 128, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-35                 [1, 512, 28, 28]          65,536\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-36            [1, 512, 28, 28]          1,024\n",
      "â”‚    â”‚    â””â”€Sequential: 3-37             [1, 512, 28, 28]          132,096\n",
      "â”‚    â”‚    â””â”€ReLU: 3-38                   [1, 512, 28, 28]          --\n",
      "â”‚    â””â”€Bottleneck: 2-5                   [1, 512, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-39                 [1, 128, 28, 28]          65,536\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-40            [1, 128, 28, 28]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-41                   [1, 128, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-42                 [1, 128, 28, 28]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-43            [1, 128, 28, 28]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-44                   [1, 128, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-45                 [1, 512, 28, 28]          65,536\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-46            [1, 512, 28, 28]          1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-47                   [1, 512, 28, 28]          --\n",
      "â”‚    â””â”€Bottleneck: 2-6                   [1, 512, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-48                 [1, 128, 28, 28]          65,536\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-49            [1, 128, 28, 28]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-50                   [1, 128, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-51                 [1, 128, 28, 28]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-52            [1, 128, 28, 28]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-53                   [1, 128, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-54                 [1, 512, 28, 28]          65,536\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-55            [1, 512, 28, 28]          1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-56                   [1, 512, 28, 28]          --\n",
      "â”‚    â””â”€Bottleneck: 2-7                   [1, 512, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-57                 [1, 128, 28, 28]          65,536\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-58            [1, 128, 28, 28]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-59                   [1, 128, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-60                 [1, 128, 28, 28]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-61            [1, 128, 28, 28]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-62                   [1, 128, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-63                 [1, 512, 28, 28]          65,536\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-64            [1, 512, 28, 28]          1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-65                   [1, 512, 28, 28]          --\n",
      "â”œâ”€Sequential: 1-7                        [1, 1024, 14, 14]         --\n",
      "â”‚    â””â”€Bottleneck: 2-8                   [1, 1024, 14, 14]         --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-66                 [1, 256, 28, 28]          131,072\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-67            [1, 256, 28, 28]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-68                   [1, 256, 28, 28]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-69                 [1, 256, 14, 14]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-70            [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-71                   [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-72                 [1, 1024, 14, 14]         262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-73            [1, 1024, 14, 14]         2,048\n",
      "â”‚    â”‚    â””â”€Sequential: 3-74             [1, 1024, 14, 14]         526,336\n",
      "â”‚    â”‚    â””â”€ReLU: 3-75                   [1, 1024, 14, 14]         --\n",
      "â”‚    â””â”€Bottleneck: 2-9                   [1, 1024, 14, 14]         --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-76                 [1, 256, 14, 14]          262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-77            [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-78                   [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-79                 [1, 256, 14, 14]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-80            [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-81                   [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-82                 [1, 1024, 14, 14]         262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-83            [1, 1024, 14, 14]         2,048\n",
      "â”‚    â”‚    â””â”€ReLU: 3-84                   [1, 1024, 14, 14]         --\n",
      "â”‚    â””â”€Bottleneck: 2-10                  [1, 1024, 14, 14]         --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-85                 [1, 256, 14, 14]          262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-86            [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-87                   [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-88                 [1, 256, 14, 14]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-89            [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-90                   [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-91                 [1, 1024, 14, 14]         262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-92            [1, 1024, 14, 14]         2,048\n",
      "â”‚    â”‚    â””â”€ReLU: 3-93                   [1, 1024, 14, 14]         --\n",
      "â”‚    â””â”€Bottleneck: 2-11                  [1, 1024, 14, 14]         --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-94                 [1, 256, 14, 14]          262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-95            [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-96                   [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-97                 [1, 256, 14, 14]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-98            [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-99                   [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-100                [1, 1024, 14, 14]         262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-101           [1, 1024, 14, 14]         2,048\n",
      "â”‚    â”‚    â””â”€ReLU: 3-102                  [1, 1024, 14, 14]         --\n",
      "â”‚    â””â”€Bottleneck: 2-12                  [1, 1024, 14, 14]         --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-103                [1, 256, 14, 14]          262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-104           [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-105                  [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-106                [1, 256, 14, 14]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-107           [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-108                  [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-109                [1, 1024, 14, 14]         262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-110           [1, 1024, 14, 14]         2,048\n",
      "â”‚    â”‚    â””â”€ReLU: 3-111                  [1, 1024, 14, 14]         --\n",
      "â”‚    â””â”€Bottleneck: 2-13                  [1, 1024, 14, 14]         --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-112                [1, 256, 14, 14]          262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-113           [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-114                  [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-115                [1, 256, 14, 14]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-116           [1, 256, 14, 14]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-117                  [1, 256, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-118                [1, 1024, 14, 14]         262,144\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-119           [1, 1024, 14, 14]         2,048\n",
      "â”‚    â”‚    â””â”€ReLU: 3-120                  [1, 1024, 14, 14]         --\n",
      "â”œâ”€Sequential: 1-8                        [1, 2048, 7, 7]           --\n",
      "â”‚    â””â”€Bottleneck: 2-14                  [1, 2048, 7, 7]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-121                [1, 512, 14, 14]          524,288\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-122           [1, 512, 14, 14]          1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-123                  [1, 512, 14, 14]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-124                [1, 512, 7, 7]            2,359,296\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-125           [1, 512, 7, 7]            1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-126                  [1, 512, 7, 7]            --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-127                [1, 2048, 7, 7]           1,048,576\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-128           [1, 2048, 7, 7]           4,096\n",
      "â”‚    â”‚    â””â”€Sequential: 3-129            [1, 2048, 7, 7]           2,101,248\n",
      "â”‚    â”‚    â””â”€ReLU: 3-130                  [1, 2048, 7, 7]           --\n",
      "â”‚    â””â”€Bottleneck: 2-15                  [1, 2048, 7, 7]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-131                [1, 512, 7, 7]            1,048,576\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-132           [1, 512, 7, 7]            1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-133                  [1, 512, 7, 7]            --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-134                [1, 512, 7, 7]            2,359,296\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-135           [1, 512, 7, 7]            1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-136                  [1, 512, 7, 7]            --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-137                [1, 2048, 7, 7]           1,048,576\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-138           [1, 2048, 7, 7]           4,096\n",
      "â”‚    â”‚    â””â”€ReLU: 3-139                  [1, 2048, 7, 7]           --\n",
      "â”‚    â””â”€Bottleneck: 2-16                  [1, 2048, 7, 7]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-140                [1, 512, 7, 7]            1,048,576\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-141           [1, 512, 7, 7]            1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-142                  [1, 512, 7, 7]            --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-143                [1, 512, 7, 7]            2,359,296\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-144           [1, 512, 7, 7]            1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-145                  [1, 512, 7, 7]            --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-146                [1, 2048, 7, 7]           1,048,576\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-147           [1, 2048, 7, 7]           4,096\n",
      "â”‚    â”‚    â””â”€ReLU: 3-148                  [1, 2048, 7, 7]           --\n",
      "â”œâ”€AdaptiveAvgPool2d: 1-9                 [1, 2048, 1, 1]           --\n",
      "â”œâ”€Linear: 1-10                           [1, 10]                   20,490\n",
      "==========================================================================================\n",
      "Total params: 23,528,522\n",
      "Trainable params: 23,528,522\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 4.09\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 177.82\n",
      "Params size (MB): 94.11\n",
      "Estimated Total Size (MB): 272.54\n",
      "==========================================================================================\n",
      "======================================================================\n",
      "\n",
      "Epoch 1 Loss=2.5206 Acc=10.86% LR=0.027878: 100%|â–ˆ| 148/148 [01:04<00:00,  2.28i\n",
      "\n",
      "Test set: Average loss: 2.8741, Accuracy: 602/3925 (15.34%)\n",
      "\n",
      "*** New best model! Test Accuracy: 15.34% ***\n",
      "âœ“ Checkpoint saved: best_model.pth\n",
      "Best Test Accuracy so far: 15.34%\n",
      "\n",
      "Epoch 2 Loss=2.1143 Acc=15.04% LR=0.045878: 100%|â–ˆ| 148/148 [01:12<00:00,  2.05i\n",
      "\n",
      "Test set: Average loss: 2.2242, Accuracy: 684/3925 (17.43%)\n",
      "\n",
      "*** New best model! Test Accuracy: 17.43% ***\n",
      "âœ“ Checkpoint saved: best_model.pth\n",
      "Best Test Accuracy so far: 17.43%\n",
      "\n",
      "Epoch 3 Loss=2.1707 Acc=18.58% LR=0.063878: 100%|â–ˆ| 148/148 [02:29<00:00,  1.01s\n",
      "\n",
      "Test set: Average loss: 2.0839, Accuracy: 1038/3925 (26.45%)\n",
      "\n",
      "*** New best model! Test Accuracy: 26.45% ***\n",
      "âœ“ Checkpoint saved: best_model.pth\n",
      "Best Test Accuracy so far: 26.45%\n",
      "\n",
      "\n",
      "ðŸ“¦ Saving final model...\n",
      "âœ“ Checkpoint saved: final_model.pth\n",
      "\n",
      "Training completed. Best test accuracy: 26.45%\n",
      "\n",
      "================================================================================\n",
      "TRAINING AND TESTING LOSS\n",
      "================================================================================\n",
      "   (Y)     ^\n",
      "3.16153949 |\n",
      "3.00346251 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "2.84538554 | \u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ¢„\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ¡€\u001b[0mâ €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "2.68730856 | â €â €â €\u001b[38;5;196mâ ˆ\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‘\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ¢\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ¢„\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ¡€\u001b[0mâ €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "2.52923159 | â €â €â €â €â €â €â €â €â €â €â €\u001b[38;5;196mâ ˆ\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‘\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ¢\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0mâ €â €â €â €â €â €â €â €â €\u001b[38;5;25mâ¢€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ¡€\u001b[0mâ €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "2.37115462 | \u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ Š\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ›\u001b[0m\u001b[38;5;196mâ ›\u001b[0m\u001b[38;5;196mâ ­\u001b[0m\u001b[38;5;196mâ ­\u001b[0m\u001b[38;5;196mâ£‰\u001b[0m\u001b[38;5;196mâ£‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ \u001b[0mâ €â €â €â €â €â €â €â €â €\u001b[38;5;25mâ ˆ\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‘\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\n",
      "2.21307764 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0mâ €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "2.05500067 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‘\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ¢\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\n",
      "1.89692369 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "1.73884672 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "1.58076974 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "1.42269277 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "1.26461579 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "1.10653882 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "0.94846185 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "0.79038487 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "0.63230790 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "0.47423092 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "0.31615395 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "0.15807697 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "         0 | â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€\n",
      "-----------|-|---------|---------|---------|---------|---------|---------|---------|-> (X)\n",
      "           | 1         1.2857143 1.5714286 1.8571429 2.1428571 2.4285714 2.7142857 3        \n",
      "\n",
      "Legend:\n",
      "-------\n",
      "\u001b[38;5;25mâ ¤â ¤ Training Loss\u001b[0m\n",
      "\u001b[38;5;196mâ ¤â ¤ Testing Loss\u001b[0m\n",
      "\n",
      "================================================================================\n",
      "TRAINING AND TESTING ACCURACY\n",
      "================================================================================\n",
      "   (Y)     ^\n",
      "       100 |\n",
      "95.5157483 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "91.0314966 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "86.5472449 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "82.0629933 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "77.5787416 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "73.0944899 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "68.6102382 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "64.1259865 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "59.6417348 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "55.1574831 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "50.6732315 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "46.1889798 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "41.7047281 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "37.2204764 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "32.7362247 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "28.2519730 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "23.7677213 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\u001b[38;5;196mâ¢€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ¡ \u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\n",
      "19.2834697 | â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ”\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ ‰\u001b[0m\u001b[38;5;196mâ \u001b[0mâ €â €â €â €â €â €â €â €â €â €\n",
      "14.7992180 | \u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ£€\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ¤\u001b[0m\u001b[38;5;196mâ ”\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ ’\u001b[0m\u001b[38;5;196mâ£’\u001b[0m\u001b[38;5;196mâ£’\u001b[0m\u001b[38;5;196mâ£’\u001b[0m\u001b[38;5;196mâ£’\u001b[0m\u001b[38;5;196mâ£’\u001b[0m\u001b[38;5;196mâ£’\u001b[0m\u001b[38;5;196mâ£Š\u001b[0m\u001b[38;5;196mâ£‰\u001b[0m\u001b[38;5;196mâ£‰\u001b[0m\u001b[38;5;196mâ£‰\u001b[0m\u001b[38;5;196mâ ­\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ”\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ Š\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\n",
      "10.3149663 | \u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ£€\u001b[0m\u001b[38;5;25mâ¡ \u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ¤\u001b[0m\u001b[38;5;25mâ ”\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ’\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0m\u001b[38;5;25mâ ‰\u001b[0mâ €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\n",
      "-----------|-|---------|---------|---------|---------|---------|---------|---------|-> (X)\n",
      "           | 1         1.2857143 1.5714286 1.8571429 2.1428571 2.4285714 2.7142857 3        \n",
      "\n",
      "Legend:\n",
      "-------\n",
      "\u001b[38;5;25mâ ¤â ¤ Training Accuracy\u001b[0m\n",
      "\u001b[38;5;196mâ ¤â ¤ Testing Accuracy\u001b[0m\n",
      "================================================================================\n",
      "\n",
      "Metrics plot saved as './checkpoints/training_curves.png'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run training on ImageNet/ImageNette\n",
    "# IMPORTANT: Update --data-dir with your actual dataset path!\n",
    "\n",
    "# Example: ImageNette training (3 epochs, quick trial)\n",
    "!python train.py --model resnet50-pytorch --dataset imagenet --data-dir ./imagenette2-160 \\\n",
    "    --epochs 3 --batch-size 64 --scheduler onecycle\n",
    "\n",
    "# Alternative commands (uncomment to use):\n",
    "\n",
    "# With LR Finder:\n",
    "# !python train.py --model resnet50 --dataset imagenet --data-dir ./imagenette2-160 \\\n",
    "#     --epochs 10 --batch-size 128 --scheduler onecycle --lr-finder\n",
    "\n",
    "# Full ImageNet (adjust path):\n",
    "# !python train.py --model resnet50 --dataset imagenet --data-dir /path/to/imagenet \\\n",
    "#     --epochs 90 --batch-size 256 --scheduler onecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Complete - View Results\n",
    "\n",
    "After training completes, you can view the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint directories found. Training may not have completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# List checkpoint directories\n",
    "import glob\n",
    "import json\n",
    "\n",
    "checkpoint_dirs = sorted(glob.glob('checkpoint_*'), reverse=True)\n",
    "\n",
    "if checkpoint_dirs:\n",
    "    latest_checkpoint = checkpoint_dirs[0]\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"LATEST CHECKPOINT: {latest_checkpoint}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Load and display metrics\n",
    "    metrics_file = os.path.join(latest_checkpoint, 'metrics.json')\n",
    "    if os.path.exists(metrics_file):\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        print(f\"Best Test Accuracy: {metrics['best_test_accuracy']:.2f}%\")\n",
    "        print(f\"Best Epoch: {metrics['best_epoch']}\")\n",
    "        print(f\"Total Epochs Trained: {len(metrics['epochs'])}\")\n",
    "        print(f\"\\nFinal Metrics:\")\n",
    "        print(f\"  - Train Accuracy: {metrics['train_accuracies'][-1]:.2f}%\")\n",
    "        print(f\"  - Test Accuracy: {metrics['test_accuracies'][-1]:.2f}%\")\n",
    "        print(f\"  - Train Loss: {metrics['train_losses'][-1]:.4f}\")\n",
    "        print(f\"  - Test Loss: {metrics['test_losses'][-1]:.4f}\")\n",
    "    \n",
    "    # List saved files\n",
    "    print(f\"\\nSaved Files in {latest_checkpoint}:\")\n",
    "    for file in sorted(os.listdir(latest_checkpoint)):\n",
    "        file_path = os.path.join(latest_checkpoint, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
    "            print(f\"  - {file} ({file_size:.2f} MB)\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "else:\n",
    "    print(\"No checkpoint directories found. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "if checkpoint_dirs:\n",
    "    latest_checkpoint = checkpoint_dirs[0]\n",
    "    \n",
    "    # Display training curves\n",
    "    curves_path = os.path.join(latest_checkpoint, 'training_curves.png')\n",
    "    if os.path.exists(curves_path):\n",
    "        print(\"Training Curves:\")\n",
    "        display(Image(filename=curves_path))\n",
    "    else:\n",
    "        print(\"Training curves not found.\")\n",
    "    \n",
    "    # Display LR Finder plot\n",
    "    lr_finder_path = os.path.join(latest_checkpoint, 'lr_finder_plot.png')\n",
    "    if os.path.exists(lr_finder_path):\n",
    "        print(\"\\nLR Finder Plot:\")\n",
    "        display(Image(filename=lr_finder_path))\n",
    "    else:\n",
    "        print(\"LR Finder plot not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Test Best Model\n",
    "\n",
    "You can load the best saved model and use it for inference or further testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if checkpoint_dirs:\n",
    "    latest_checkpoint = checkpoint_dirs[0]\n",
    "    best_model_path = os.path.join(latest_checkpoint, 'best_model.pth')\n",
    "    \n",
    "    if os.path.exists(best_model_path):\n",
    "        # Load the checkpoint with weights_only=False for PyTorch 2.6+\n",
    "        checkpoint = torch.load(best_model_path, map_location='cpu', weights_only=False)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"BEST MODEL CHECKPOINT INFORMATION\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Epoch: {checkpoint['epoch']}\")\n",
    "        print(f\"Train Accuracy: {checkpoint['train_accuracy']:.2f}%\")\n",
    "        print(f\"Test Accuracy: {checkpoint['test_accuracy']:.2f}%\")\n",
    "        print(f\"Train Loss: {checkpoint['train_loss']:.4f}\")\n",
    "        print(f\"Test Loss: {checkpoint['test_loss']:.4f}\")\n",
    "        print(f\"Timestamp: {checkpoint['timestamp']}\")\n",
    "        \n",
    "        print(f\"\\nModel Configuration:\")\n",
    "        for key, value in checkpoint['config'].items():\n",
    "            print(f\"  - {key}: {value}\")\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Load model using the new modular structure\n",
    "        from models import get_model\n",
    "        \n",
    "        model_name = checkpoint['config'].get('model', 'resnet50')\n",
    "        model = get_model(model_name, num_classes=100)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        print(f\"âœ“ Model '{model_name}' loaded successfully from modular structure\")\n",
    "        print(\"âœ“ Model ready for inference\")\n",
    "    else:\n",
    "        print(\"âš  Best model checkpoint not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training on **ImageNet/ImageNette** is complete using the **modular codebase**!\n",
    "\n",
    "### ðŸ“ Checkpoint Files:\n",
    "- **Best Model**: `checkpoint_N/best_model.pth` - Model with best test accuracy\n",
    "- **Training Curves**: `checkpoint_N/training_curves.png` - Metrics visualization\n",
    "- **LR Finder Plot**: `checkpoint_N/lr_finder_plot.png` - LR range test (if enabled)\n",
    "- **Metrics**: `checkpoint_N/metrics.json` - Complete training history\n",
    "- **Config**: `checkpoint_N/config.json` - Training configuration\n",
    "- **Model Card**: `checkpoint_N/README.md` - Detailed documentation\n",
    "\n",
    "### ðŸ—ï¸ Modular Structure:\n",
    "- **Data Loaders** (`data_loaders/`) - CIFAR-100, ImageNet, easy to add more\n",
    "- **Models** (`models/`) - ResNet50, WideResNet, clean separation\n",
    "- **Training** (`training/`) - Reusable optimizer, scheduler, LR finder\n",
    "- **Utils** (`utils/`) - Checkpointing, metrics, HuggingFace upload\n",
    "\n",
    "### ðŸŽ¯ Model Usage:\n",
    "```python\n",
    "import torch\n",
    "from models import get_model\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('checkpoint_N/best_model.pth', \n",
    "                       map_location='cpu', weights_only=False)\n",
    "\n",
    "# Get model (num_classes auto-detected during training)\n",
    "num_classes = checkpoint['config'].get('num_classes', 10)  # 10 for ImageNette, 1000 for ImageNet-1K\n",
    "model = get_model('resnet50', num_classes=num_classes)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "### ðŸ“Š Supported Datasets:\n",
    "- **CIFAR-100**: 100 classes, 32x32 images\n",
    "- **ImageNet-1K**: 1000 classes, 224x224 (resized)\n",
    "- **ImageNette**: 10 classes, ImageNet subset\n",
    "- **Custom**: Any ImageFolder-compatible dataset\n",
    "\n",
    "### ðŸ†• Available Models:\n",
    "- `resnet50` - ResNet-50 (25.6M parameters)\n",
    "- `wideresnet28-10` - WideResNet-28-10 (36.5M parameters)\n",
    "\n",
    "---\n",
    "\n",
    "**Modular design makes experimentation easy!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erav4-sess9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
