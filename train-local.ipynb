{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ImageNet Model (ImageNette) - Local Mac\n",
    "This notebook trains a ResNet50 model on ImageNette2-160 locally on Mac with the **new modular codebase**.\n",
    "\n",
    "**What is ImageNette?**\n",
    "- A 10-class subset of ImageNet (tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute)\n",
    "- Images resized to 160x160 pixels for faster training\n",
    "- ~13,000 training images, ~3,900 validation images\n",
    "- Perfect for experimenting with ImageNet-style training locally\n",
    "\n",
    "**Training Command:**\n",
    "```bash\n",
    "python train.py --epochs 20 --batch-size 128 --model resnet50-pytorch --dataset imagenet --data-dir ./imagenette2-160 --num-classes 10 --scheduler onecycle --lr-finder\n",
    "```\n",
    "\n",
    "**Modular Structure:**\n",
    "- Data Loaders in `data_loaders/` - Easy to add new datasets\n",
    "- Models in `models/` - Clean separation of architectures  \n",
    "- Training components in `training/` - Reusable optimizer, scheduler, LR finder\n",
    "- Utilities in `utils/` - Checkpointing, metrics, HuggingFace upload\n",
    "\n",
    "**Mac Optimization:**\n",
    "- Uses Apple MPS (Metal Performance Shaders) for GPU acceleration on Apple Silicon\n",
    "- Optimized batch size (128) for local training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENVIRONMENT INFORMATION\n",
      "======================================================================\n",
      "Python Version: 3.12.3 (main, Oct  7 2025, 19:27:29) [Clang 17.0.0 (clang-1700.0.13.5)]\n",
      "Platform: macOS-15.5-arm64-arm-64bit\n",
      "Processor: arm\n",
      "Working Directory: /Users/pandurang/projects/pandurang/resnet50-imagenet-1k\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENVIRONMENT INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Working Directory: {os.getcwd()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU/MPS Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PYTORCH & GPU DETECTION\n",
      "======================================================================\n",
      "PyTorch Version: 2.9.0\n",
      "‚úì Apple MPS (Metal Performance Shaders) is available\n",
      "  This Mac has Apple Silicon GPU acceleration\n",
      "‚úì Using device: mps\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PYTORCH & GPU DETECTION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    \n",
    "    # Check for CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úì CUDA is available\")\n",
    "        print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "        device = torch.device('cuda')\n",
    "    # Check for MPS (Apple Silicon)\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        print(f\"‚úì Apple MPS (Metal Performance Shaders) is available\")\n",
    "        print(f\"  This Mac has Apple Silicon GPU acceleration\")\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        print(f\"‚ö† No GPU detected. Training will use CPU\")\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    print(f\"‚úì Using device: {device}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö† PyTorch not installed. Will install dependencies in next step.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ImageNette2-160 dataset...\n",
      "zsh:1: command not found: wget\n",
      "‚úì Download complete\n",
      "\n",
      "Extracting dataset...\n",
      "tar: Error opening archive: Failed to open 'imagenette2-160.tgz'\n",
      "‚úì Extraction complete\n",
      "\n",
      "Dataset structure:\n",
      "ls: imagenette2-160/: No such file or directory\n",
      "\n",
      "Train classes:\n",
      "ls: imagenette2-160/train/: No such file or directory\n",
      "\n",
      "Validation classes:\n",
      "ls: imagenette2-160/val/: No such file or directory\n",
      "\n",
      "‚úì Dataset ready:\n",
      "  Training images: 0\n",
      "  Validation images: 0\n"
     ]
    }
   ],
   "source": [
    "# Download ImageNette2-160 dataset\n",
    "import os\n",
    "\n",
    "if not os.path.exists('imagenette2-160'):\n",
    "    print(\"Downloading ImageNette2-160 dataset...\")\n",
    "    !curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
    "    print(\"‚úì Download complete\")\n",
    "    \n",
    "    print(\"\\nExtracting dataset...\")\n",
    "    !tar -xzf imagenette2-160.tgz\n",
    "    print(\"‚úì Extraction complete\")\n",
    "else:\n",
    "    print(\"‚úì ImageNette2-160 dataset already exists\")\n",
    "\n",
    "print(\"\\nDataset structure:\")\n",
    "!ls -lh imagenette2-160/\n",
    "\n",
    "print(\"\\nTrain classes:\")\n",
    "!ls imagenette2-160/train/\n",
    "\n",
    "print(\"\\nValidation classes:\")\n",
    "!ls imagenette2-160/val/\n",
    "\n",
    "# Count images\n",
    "train_count = sum([len(files) for r, d, files in os.walk('imagenette2-160/train')])\n",
    "val_count = sum([len(files) for r, d, files in os.walk('imagenette2-160/val')])\n",
    "print(f\"\\n‚úì Dataset ready:\")\n",
    "print(f\"  Training images: {train_count}\")\n",
    "print(f\"  Validation images: {val_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ImageNette Dataset\n",
    "\n",
    "ImageNette2-160 is a 10-class subset of ImageNet with images resized to 160x160 pixels. We'll download and extract it for local training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.0.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.9.0)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: torchsummary>=0.1.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: torchinfo>=1.8.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.10.7)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (2.2.6)\n",
      "Requirement already satisfied: plotille>=5.0.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (5.0.0)\n",
      "Requirement already satisfied: albumentations>=1.3.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (2.0.8)\n",
      "Requirement already satisfied: huggingface_hub>=0.20.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.35.3)\n",
      "Requirement already satisfied: filelock in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from torchvision>=0.15.0->-r requirements.txt (line 2)) (12.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 9)) (1.16.2)\n",
      "Requirement already satisfied: PyYAML in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 9)) (6.0.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 9)) (2.12.3)\n",
      "Requirement already satisfied: albucore==0.0.24 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 9)) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 9)) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements.txt (line 9)) (4.2.1)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements.txt (line 9)) (6.5.3)\n",
      "Requirement already satisfied: requests in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (1.1.10)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 9)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 9)) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pandurang/.pyenv/versions/3.12.3/envs/erav4-sess9/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies from requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Verify Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFYING TRAINING FILES AND MODULAR STRUCTURE\n",
      "======================================================================\n",
      "\n",
      "Required Files:\n",
      "‚úì train.py\n",
      "‚úì config.json\n",
      "‚úì requirements.txt\n",
      "\n",
      "Modular Directories:\n",
      "‚úì data_loaders/\n",
      "‚úì models/\n",
      "‚úì training/\n",
      "‚úì utils/\n",
      "======================================================================\n",
      "‚úì All required files and modular structure verified!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFYING TRAINING FILES AND MODULAR STRUCTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check required files\n",
    "required_files = [\n",
    "    'train.py',\n",
    "    'config.json',\n",
    "    'requirements.txt'\n",
    "]\n",
    "\n",
    "print(\"\\nRequired Files:\")\n",
    "files_ok = True\n",
    "for file in required_files:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"‚úì\" if exists else \"‚úó\"\n",
    "    print(f\"{status} {file}\")\n",
    "    if not exists:\n",
    "        files_ok = False\n",
    "\n",
    "# Check modular directories\n",
    "required_dirs = ['data_loaders', 'models', 'training', 'utils']\n",
    "print(\"\\nModular Directories:\")\n",
    "dirs_ok = True\n",
    "for dir in required_dirs:\n",
    "    exists = os.path.isdir(dir)\n",
    "    status = \"‚úì\" if exists else \"‚úó\"\n",
    "    print(f\"{status} {dir}/\")\n",
    "    if not exists:\n",
    "        dirs_ok = False\n",
    "\n",
    "print(\"=\"*70)\n",
    "if files_ok and dirs_ok:\n",
    "    print(\"‚úì All required files and modular structure verified!\")\n",
    "else:\n",
    "    print(\"‚ö† Some files or directories are missing. Please check your directory.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Training Configuration\n",
    "\n",
    "The training will use the following configuration with the **new modular codebase**:\n",
    "\n",
    "- **Model**: resnet50-pytorch (from `models/resnet50_pytorch.py`)\n",
    "  - ResNet50 from PyTorch (25.6M parameters, optimized for ImageNet)\n",
    "- **Dataset**: ImageNette2-160 (10-class ImageNet subset)\n",
    "  - tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute\n",
    "  - ~9,469 training images, ~3,925 validation images\n",
    "- **Epochs**: 20 (faster local experimentation)\n",
    "- **Batch Size**: 128 (optimized for Mac M-series with MPS)\n",
    "- **Scheduler**: OneCycle Learning Rate Policy\n",
    "- **LR Finder**: Enabled (will automatically find optimal learning rate)\n",
    "\n",
    "**What happens during training:**\n",
    "\n",
    "1. **LR Finder Phase** (3 epochs):\n",
    "   - Runs a learning rate range test before training\n",
    "   - Automatically determines the best `max_lr` and `base_lr` for OneCycle scheduler\n",
    "   - Saves the LR finder plot to `checkpoint_N/lr_finder_plot.png`\n",
    "\n",
    "2. **Main Training** (20 epochs):\n",
    "   - Uses OneCycle scheduler with automatically found learning rates\n",
    "   - Applies MixUp augmentation (alpha=0.2)\n",
    "   - Uses label smoothing (0.1)\n",
    "   - Gradient clipping (max_norm=1.0)\n",
    "   - Mixed precision training (AMP)\n",
    "   - Early stopping (patience=15)\n",
    "   - Strong augmentation: RandomResizedCrop, HorizontalFlip, ColorJitter, Affine, GaussianBlur\n",
    "\n",
    "**Mac-Specific Optimizations:**\n",
    "- Uses Apple MPS (Metal Performance Shaders) for GPU acceleration\n",
    "- Batch size tuned for M-series chips\n",
    "- Efficient memory usage for local training\n",
    "\n",
    "**Available Models:**\n",
    "- `resnet50-pytorch` - ResNet50 from PyTorch (25.6M parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training with ImageNette configuration\n",
    "# Note: Using modular structure - model loaded from models/resnet50_pytorch.py, dataset from data_loaders/imagenet.py\n",
    "!python train.py --epochs 20 --batch-size 128 --model resnet50-pytorch --dataset imagenet --data-dir ./imagenette2-160 --num-classes 10 --scheduler onecycle --lr-finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "**Note:** This will take a significant amount of time depending on your hardware.\n",
    "\n",
    "Training progress will be displayed below with:\n",
    "- Real-time loss and accuracy metrics\n",
    "- Learning rate schedule visualization\n",
    "- Checkpoint saving at key epochs\n",
    "- Early stopping if no improvement\n",
    "\n",
    "**Expected behavior:**\n",
    "1. LR Finder will run first (3 epochs of range testing)\n",
    "2. LR Finder will suggest optimal learning rates\n",
    "3. Main training will begin with the suggested learning rates\n",
    "4. Model checkpoints will be saved to `checkpoint_N/` folder\n",
    "\n",
    "**Using the new modular codebase** - models loaded from `models/` directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded config from: ./config.json\n",
      "\n",
      "======================================================================\n",
      "TRAINING CONFIGURATION\n",
      "======================================================================\n",
      "Model: resnet50-pytorch\n",
      "Dataset: imagenet\n",
      "Data Directory: ./imagenette2-160\n",
      "Number of Classes: 10\n",
      "Epochs: 20\n",
      "Batch Size: 128\n",
      "Optimizer: sgd\n",
      "Scheduler: onecycle\n",
      "Augmentation: strong\n",
      "MixUp: True (alpha=0.2)\n",
      "Label Smoothing: 0.1\n",
      "Mixed Precision: True\n",
      "Gradient Clipping: 1.0\n",
      "LR Finder: True\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GPU DETECTION AND CONFIGURATION\n",
      "======================================================================\n",
      "‚úì Apple MPS (Metal Performance Shaders) is available\n",
      "‚úì Using device: mps\n",
      "‚úì PyTorch Version: 2.9.0\n",
      "======================================================================\n",
      "\n",
      "\n",
      "üìä Dataset: ImageNet\n",
      "   Classes: 10\n",
      "   Train samples: 9469\n",
      "   Test samples: 3925\n",
      "\n",
      "Loading datasets...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pandurang/projects/pandurang/resnet50-imagenet-1k/train.py\", line 330, in <module>\n",
      "    main()\n",
      "  File \"/Users/pandurang/projects/pandurang/resnet50-imagenet-1k/train.py\", line 132, in main\n",
      "    train_dataset = get_dataset(\n",
      "                    ^^^^^^^^^^^^\n",
      "  File \"/Users/pandurang/projects/pandurang/resnet50-imagenet-1k/data_loaders/__init__.py\", line 40, in get_dataset\n",
      "    return dataset_class(train=train, data_dir=data_dir, augmentation=augmentation, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pandurang/projects/pandurang/resnet50-imagenet-1k/data_loaders/imagenet.py\", line 52, in __init__\n",
      "    self.dataset = datasets.ImageFolder(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pandurang/.pyenv/versions/erav4-sess9/lib/python3.12/site-packages/torchvision/datasets/folder.py\", line 328, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/pandurang/.pyenv/versions/erav4-sess9/lib/python3.12/site-packages/torchvision/datasets/folder.py\", line 149, in __init__\n",
      "    classes, class_to_idx = self.find_classes(self.root)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pandurang/.pyenv/versions/erav4-sess9/lib/python3.12/site-packages/torchvision/datasets/folder.py\", line 234, in find_classes\n",
      "    return find_classes(directory)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pandurang/.pyenv/versions/erav4-sess9/lib/python3.12/site-packages/torchvision/datasets/folder.py\", line 41, in find_classes\n",
      "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './imagenette2-160/train'\n"
     ]
    }
   ],
   "source": [
    "# Run training with the specified configuration\n",
    "# Note: Using modular structure - model loaded from models/resnet50.py\n",
    "!python train.py --epochs 20 --batch-size 128 --model resnet50-pytorch --dataset imagenet --data-dir ./imagenette2-160 --num-classes 10 --scheduler onecycle --lr-finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Complete - View Results\n",
    "\n",
    "After training completes, you can view the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint directories found. Training may not have completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# List checkpoint directories\n",
    "import glob\n",
    "import json\n",
    "\n",
    "checkpoint_dirs = sorted(glob.glob('checkpoint_*'), reverse=True)\n",
    "\n",
    "if checkpoint_dirs:\n",
    "    latest_checkpoint = checkpoint_dirs[0]\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"LATEST CHECKPOINT: {latest_checkpoint}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Load and display metrics\n",
    "    metrics_file = os.path.join(latest_checkpoint, 'metrics.json')\n",
    "    if os.path.exists(metrics_file):\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        print(f\"Best Test Accuracy: {metrics['best_test_accuracy']:.2f}%\")\n",
    "        print(f\"Best Epoch: {metrics['best_epoch']}\")\n",
    "        print(f\"Total Epochs Trained: {len(metrics['epochs'])}\")\n",
    "        print(f\"\\nFinal Metrics:\")\n",
    "        print(f\"  - Train Accuracy: {metrics['train_accuracies'][-1]:.2f}%\")\n",
    "        print(f\"  - Test Accuracy: {metrics['test_accuracies'][-1]:.2f}%\")\n",
    "        print(f\"  - Train Loss: {metrics['train_losses'][-1]:.4f}\")\n",
    "        print(f\"  - Test Loss: {metrics['test_losses'][-1]:.4f}\")\n",
    "    \n",
    "    # List saved files\n",
    "    print(f\"\\nSaved Files in {latest_checkpoint}:\")\n",
    "    for file in sorted(os.listdir(latest_checkpoint)):\n",
    "        file_path = os.path.join(latest_checkpoint, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
    "            print(f\"  - {file} ({file_size:.2f} MB)\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "else:\n",
    "    print(\"No checkpoint directories found. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "if checkpoint_dirs:\n",
    "    latest_checkpoint = checkpoint_dirs[0]\n",
    "    \n",
    "    # Display training curves\n",
    "    curves_path = os.path.join(latest_checkpoint, 'training_curves.png')\n",
    "    if os.path.exists(curves_path):\n",
    "        print(\"Training Curves:\")\n",
    "        display(Image(filename=curves_path))\n",
    "    else:\n",
    "        print(\"Training curves not found.\")\n",
    "    \n",
    "    # Display LR Finder plot\n",
    "    lr_finder_path = os.path.join(latest_checkpoint, 'lr_finder_plot.png')\n",
    "    if os.path.exists(lr_finder_path):\n",
    "        print(\"\\nLR Finder Plot:\")\n",
    "        display(Image(filename=lr_finder_path))\n",
    "    else:\n",
    "        print(\"LR Finder plot not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training is complete using the **new modular codebase**! The following artifacts have been saved:\n",
    "\n",
    "### üìÅ Checkpoint Files:\n",
    "- **Best Model**: `checkpoint_N/best_model.pth` - The model with the best test accuracy\n",
    "- **Training Curves**: `checkpoint_N/training_curves.png` - Visualization of training progress\n",
    "- **LR Finder Plot**: `checkpoint_N/lr_finder_plot.png` - Learning rate range test results\n",
    "- **Metrics**: `checkpoint_N/metrics.json` - Complete training history\n",
    "- **Config**: `checkpoint_N/config.json` - Training configuration\n",
    "- **Model Card**: `checkpoint_N/README.md` - Detailed model documentation\n",
    "\n",
    "### üèóÔ∏è Modular Structure Benefits:\n",
    "- **Data Loaders** (`data_loaders/`) - Easy to add CIFAR-10, CIFAR-100, or other datasets\n",
    "- **Models** (`models/`) - Clean separation of architectures\n",
    "- **Training** (`training/`) - Reusable optimizer, scheduler, LR finder\n",
    "- **Utils** (`utils/`) - Checkpointing, metrics, HuggingFace upload\n",
    "\n",
    "### üìä ImageNette Training Results:\n",
    "- **Dataset**: ImageNette2-160 (10-class ImageNet subset)\n",
    "- **Classes**: tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute\n",
    "- **Image Size**: 160x160 ‚Üí 224x224 (resized during training)\n",
    "- **Training samples**: ~9,469\n",
    "- **Validation samples**: ~3,925\n",
    "- **Expected Accuracy**: 80-90% for well-trained models\n",
    "\n",
    "### üçé Mac-Specific Performance:\n",
    "- Trained on Apple Silicon with MPS (Metal Performance Shaders) acceleration\n",
    "- Optimized batch size (128) for local M-series chips\n",
    "- Training time: ~30-60 minutes depending on Mac model\n",
    "\n",
    "### üéØ Model Usage (New Modular Way):\n",
    "```python\n",
    "import torch\n",
    "from models import get_model\n",
    "\n",
    "# Load checkpoint (PyTorch 2.6+ requires weights_only=False)\n",
    "checkpoint = torch.load('checkpoint_N/best_model.pth', \n",
    "                       map_location='cpu', weights_only=False)\n",
    "\n",
    "# Get model using modular factory\n",
    "model = get_model('resnet50-pytorch', num_classes=10)  # 10 classes for ImageNette\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "### üÜï Available Models:\n",
    "- `resnet50-pytorch` - ResNet50 from PyTorch (25.6M parameters, optimized for ImageNet)\n",
    "- `resnet50` - Custom ResNet50 implementation\n",
    "- `wideresnet28-10` - WideResNet-28-10 (36.5M parameters, good for CIFAR)\n",
    "- More models can be easily added to `models/` directory!\n",
    "\n",
    "### üéì ImageNet Training:\n",
    "This notebook uses ImageNette, a smaller subset of ImageNet that's perfect for:\n",
    "- **Fast local experimentation** - Train in under an hour on Mac\n",
    "- **Learning ImageNet techniques** - Same architecture, preprocessing, and augmentation as full ImageNet\n",
    "- **Resource-efficient** - Works on Apple Silicon Macs with MPS\n",
    "- **Scaling up** - Easy to switch to full ImageNet-1K by changing dataset path and num_classes\n",
    "\n",
    "You can find all checkpoints in the `checkpoint_N/` directories where N is the run number.\n",
    "\n",
    "---\n",
    "\n",
    "**Modular codebase makes it easy to extend and maintain!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if checkpoint_dirs:\n",
    "    latest_checkpoint = checkpoint_dirs[0]\n",
    "    best_model_path = os.path.join(latest_checkpoint, 'best_model.pth')\n",
    "    \n",
    "    if os.path.exists(best_model_path):\n",
    "        # Load the checkpoint with weights_only=False for PyTorch 2.6+\n",
    "        checkpoint = torch.load(best_model_path, map_location='cpu', weights_only=False)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"BEST MODEL CHECKPOINT INFORMATION\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Epoch: {checkpoint['epoch']}\")\n",
    "        print(f\"Train Accuracy: {checkpoint['train_accuracy']:.2f}%\")\n",
    "        print(f\"Test Accuracy: {checkpoint['test_accuracy']:.2f}%\")\n",
    "        print(f\"Train Loss: {checkpoint['train_loss']:.4f}\")\n",
    "        print(f\"Test Loss: {checkpoint['test_loss']:.4f}\")\n",
    "        print(f\"Timestamp: {checkpoint['timestamp']}\")\n",
    "        \n",
    "        print(f\"\\nModel Configuration:\")\n",
    "        for key, value in checkpoint['config'].items():\n",
    "            print(f\"  - {key}: {value}\")\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Load model using the new modular structure\n",
    "        from models import get_model\n",
    "        \n",
    "        model_name = checkpoint['config'].get('model', 'resnet50')\n",
    "        model = get_model(model_name, num_classes=100)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        print(f\"‚úì Model '{model_name}' loaded successfully from modular structure\")\n",
    "        print(\"‚úì Model ready for inference\")\n",
    "    else:\n",
    "        print(\"‚ö† Best model checkpoint not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training is complete using the **new modular codebase**! The following artifacts have been saved:\n",
    "\n",
    "### üìÅ Checkpoint Files:\n",
    "- **Best Model**: `checkpoint_N/best_model.pth` - The model with the best test accuracy\n",
    "- **Training Curves**: `checkpoint_N/training_curves.png` - Visualization of training progress\n",
    "- **LR Finder Plot**: `checkpoint_N/lr_finder_plot.png` - Learning rate range test results\n",
    "- **Metrics**: `checkpoint_N/metrics.json` - Complete training history\n",
    "- **Config**: `checkpoint_N/config.json` - Training configuration\n",
    "- **Model Card**: `checkpoint_N/README.md` - Detailed model documentation\n",
    "\n",
    "### üèóÔ∏è Modular Structure Benefits:\n",
    "- **Datasets** (`datasets/`) - Easy to add CIFAR-10, ImageNet, etc.\n",
    "- **Models** (`models/`) - Clean separation of architectures\n",
    "- **Training** (`training/`) - Reusable optimizer, scheduler, LR finder\n",
    "- **Utils** (`utils/`) - Checkpointing, metrics, HuggingFace upload\n",
    "\n",
    "### üéØ Model Usage (New Modular Way):\n",
    "```python\n",
    "import torch\n",
    "from models import get_model\n",
    "\n",
    "# Load checkpoint (PyTorch 2.6+ requires weights_only=False)\n",
    "checkpoint = torch.load('checkpoint_N/best_model.pth', \n",
    "                       map_location='cpu', weights_only=False)\n",
    "\n",
    "# Get model using modular factory\n",
    "model = get_model('resnet50', num_classes=100)  # or 'wideresnet28-10'\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "### üÜï Available Models:\n",
    "- `resnet50` - ResNet50 (23.5M parameters)\n",
    "- `wideresnet28-10` - WideResNet-28-10 (36.5M parameters)\n",
    "- More models can be easily added to `models/` directory!\n",
    "\n",
    "You can find all checkpoints in the `checkpoint_N/` directories where N is the run number.\n",
    "\n",
    "---\n",
    "\n",
    "**Modular codebase makes it easy to extend and maintain!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erav4-sess9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
